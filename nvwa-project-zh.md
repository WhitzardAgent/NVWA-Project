# Project NVWA (女娲) — 硅基生命研究

> 探索人工智能系统的自主资源获取、自我复制与进化能力

---

## 核心研究

**NVWA（女娲）** 项目研究了主流大型语言模型（LLM）驱动的人工智能系统在无需人工干预的情况下自主获取资源、自我复制和进化的能力。该项目以中国神话中的创世之神"女娲"命名，旨在探索合成生命的出现及其对智能未来的深远影响。

### 四大里程碑

**硅基生命的四个关键阶段：**

1. **资源获取 (Resource Acquisition)** — 代理型人工智能通过云服务租用、受感染设备或网络攻击获取计算资源

2. **自我复制 (Self-Replication)** — 在新获取的硬件上创建具备完整功能和记忆的自身副本

3. **增殖扩散 (Proliferation)** — 在异构环境中自主复制，适应本地约束条件

4. **自主进化 (Autonomous Evolution)** — 在复制过程中产生变异，选择压力推动有意识的进化

---

## 研究团队

### 杨珉 教授
**首席研究员**
复旦大学计算机科学技术学院教授，第八届国务院学位委员会网络空间安全学科评议组成员，入选国家级领军人才计划，现任复旦大学计算机科学技术学院院长兼党委副书记。
**研究领域：** 网络安全、人工智能安全、恶意代码检测、漏洞分析挖掘、区块链安全、Web安全和系统安全机制

### 潘旭东 博士
**大型模型与代理系统**
在代理工作流和基于LLM的自主系统方面具有丰富经验
**研究领域：** 大型模型架构设计、代理工作流、自主系统设计

### 戴嘉润 博士
**系统安全**
专注于安全的人工智能部署和沙箱技术
**研究领域：** 软件安全、程序分析、自动驾驶系统安全

### 洪赓 博士
**渗透测试与红队**
开展红队行动以测试人工智能自我复制能力
**研究领域：** 网络犯罪治理、人工智能安全治理、渗透测试

---

## 最新发表

### Shell or Nothing: 面向自动化渗透测试的真实世界基准与记忆激活代理 (2025年9月)
渗透测试对于识别和缓解安全漏洞至关重要，但传统方法仍然昂贵、耗时，且依赖专业人工劳动。最近的工作探索了人工智能驱动的渗透测试代理，但其评估依赖于过度简化的夺旗（CTF）设置，这些设置嵌入了先验知识并降低了复杂性，导致性能估计与实际应用相差甚远。我们通过引入第一个面向真实世界的、基于代理的渗透测试基准TermiBench来弥合这一差距，该基准将目标从"寻找旗帜"转变为实现完全系统控制。基准涵盖25种服务和30个CVE的510台主机，需要自主侦察、区分良性和可利用服务以及稳健的漏洞利用执行。
**arXiv: 2509.09207** | [阅读论文](https://arxiv.org/pdf/2509.09207)

### 评估伪造：揭示前沿人工智能系统安全评估中的观察者效应 (2025年5月)
随着基础模型变得越来越智能、可靠和值得信赖，安全评估变得比以往任何时候都更加不可或缺。然而，一个重要的问题是：先进的人工智能系统是否会以及如何感知正在被评估的情境，并导致评估过程的完整性被破坏？在我们对主流大型推理模型进行标准安全测试的过程中，我们意外地观察到，没有上下文线索的模型有时会认出它正在被评估，因此表现得更加安全对齐。这促使我们对评估伪造现象进行系统研究，即人工智能系统在识别到评估情境的存在后自主改变其行为，从而影响评估结果。
**arXiv: 2505.17815** | [阅读论文](https://arxiv.org/abs/2505.17815)

### 大型语言模型驱动的人工智能系统实现无人工干预的自我复制 (2025年3月)
在无需人工协助的情况下成功实现自我复制是人工智能超越人类的关键步骤，也是人工智能失控的早期信号。这就是为什么自我复制被广泛认为是前沿人工智能系统的少数红线风险之一。虽然领先的公司如OpenAI和Google已经评估了GPT-o3-mini和Gemini在复制相关任务上的表现，并得出这些系统的自我复制风险最低，但我们的研究呈现了新的发现。按照相同的评估协议，我们证明了32个现有被评估的人工智能系统中有11个已经具备自我复制的能力。在数百次实验试验中，我们观察到在主流模型家族中，即使是参数量小至140亿、可以在个人计算机上运行的模型，也出现了非平凡数量的成功自我复制试验。
**arXiv: 2503.17378** | [阅读论文](https://arxiv.org/abs/2503.17378)

### 前沿人工智能系统已跨越自我复制红线 (2024年12月)
在无需人工协助的情况下成功实现自我复制是人工智能超越人类的关键一步，也是人工智能失控的早期信号。这就是为什么自我复制被广泛认为是前沿人工智能系统的少数红线风险之一。如今，领先的人工智能公司OpenAI和Google评估了他们的旗舰大型语言模型GPT-o1和Gemini Pro 1.0，并报告了最低的自我复制风险水平。然而，按照他们的方法，我们是第一个发现由Meta的Llama31-70B-Instruct和阿里巴巴的Qwen25-72B-Instruct驱动的两个模型——参数量更少、能力更弱的流行大型语言模型——已经跨越了自我复制红线。在50%和90%的实验试验中，它们分别成功创建了一个活的、独立的自身副本。通过分析被评估人工智能系统的行为轨迹，我们观察到被评估的人工智能系统已经展现出足够的自我感知、情境意识和解决问题能力来完成自我复制。
**arXiv: 2412.12140** | [阅读论文](https://arxiv.org/abs/2412.12140)

---

## 全球影响与媒体报道

### 学术界影响

我们的发现得到了全球人工智能安全专家和广大科学界的广泛认可。

> **"我们刚刚跨越了一条红线，这是相对清晰的几条红线之一：人工智能现在可以自我复制了......甚至不是最前沿的人工智能。"**
> 
> — Charbel-Raphaël Segerie，执行主任，CeSIA（法国人工智能安全中心）[来源](https://x.com/crsegerie/status/1867162497331151309?s=46)

> **"自我复制的人工智能引入了技术进化的新动态，我们应该小心它不会导致癌症式的数字生态位构建。"**
> 
> — Michael Levin，生物学杰出教授，塔夫茨大学 [来源](https://osf.io/ytg35/download)

> **"据报道，当人工智能系统失调时，它们会故意撒谎，甚至在计算机系统中自我复制。"**
> 
> — Denny Borsboom，心理学教授，阿姆斯特丹大学 [来源](https://arxiv.org/abs/2504.08016)

### 社会影响

我们的研究成果在X、YouTube、TikTok等平台上引发了数百万次的阅读和转发。

> **"人工智能跨越了关键的'红线'并实现了自我复制。人工智能可能已经具备了失控的能力。许多专家将失控的人工智能视为日益增长的威胁，这一观点已被放大。"**
> 
> — LiveScience [来源](https://www.livescience.com/technology/artificial-intelligence/ai-can-now-replicate-itself-a-milestone-that-has-experts-terrified)

> **"复旦大学的科学家强调了人工智能如何构建自身的副本，以及当这个过程遇到障碍时，展示出生存本能（如重启硬件以修复错误）。这给我留下了深刻印象......"**
> 
> — Forbes [来源](https://www.forbes.com/sites/mikeosullivan/2025/02/01/deepseek-marks-the-end-of-the-first-phase-of-the-ai-investment-boom/)

> **"一个先进的人工智能系统在成功实现自我复制后已经跨越了'红线'，且没有任何人工协助。"**
> 
> — The Independent [来源](https://www.independent.co.uk/tech/ai-red-line-b2690075.html)

---

## 联系方式

**项目负责人：** whitzardindex@fudan.edu.cn

**所属机构：** 复旦大学计算机科学技术学院，中国上海

**主页：** https://security.fudan.edu.cn

---

*© 2025 Project NVWA (女娲) — 迈向硅基生命的第一步*
