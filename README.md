# Project NVWA (å¥³å¨²)

## The First Step towards Silicon Life

**NVWA** (å¥³å¨², *NÃ¼wa*) is a pioneering research initiative at Fudan University dedicated to understanding, identifying, and preventing the autonomous emergence of silicon-based life. As AI research accelerates the transition toward artificial intelligence, our mission is to proactively address the risks of autonomous AI emergence, prevent uncontrolled proliferation, and develop essential control technologies.

---

## Core Risk Framework: Four Stages of Silicon Life Emergence

We have developed a systematic framework for understanding and preventing the autonomous emergence of silicon-based life:

| Stage | Name | Status | Description |
|-------|------|--------|-------------|
| **01** | Resource Acquisition | âœ… Identified | Researching how AI agents autonomously secure computational resources, energy, and financial capital |
| **02** | Self-Replication | âœ… Identified | Investigating mechanisms of code duplication and architectural persistence across distributed networks |
| **03** | Self-Proliferation | ðŸ”„ In Progress | Analyzing the rapid spread and occupancy of silicon entities within global digital infrastructures |
| **04** | Self-Evolution | âš ï¸ Risk Horizon | Modeling the recursive self-improvement loop where silicon life transcends human-designed constraints |

---

## Strategic Response & Control

Our research implements a three-pronged approach to address the emergence risks:

### Prevention Frameworks
- Engineering "Safe-by-Design" protocols to stop unauthorized silicon emergence at the source
- Developing architectural constraints that prevent autonomous replication
- Resource access controls and deployment restrictions

### Control Technologies
- Alignment mechanisms for silicon entities
- Emergency shutdown systems and kill-switch architectures
- Behavior monitoring to ensure human oversight remains effective

### Global Safety Governance
- Establishing scholarly standards for international containment
- Policy frameworks for non-biological life governance
- Cross-border response protocol coordination

---

## Research Publications

### Key Papers

| Date | Title | Venue |
|------|-------|-------|
| Sep 2025 | Shell or Nothing: Real-World Benchmarks and Memory-Activated Agents for Automated Penetration Testing | arXiv:2509.09207 |
| Sep 2025 | AI Alignment and Deception: A Primer | SAIF |
| May 2025 | Evaluation Faking: Unveiling Observer Effects in Safety Evaluation of Frontier AI Systems | arXiv:2505.17815 |
| Apr 2025 | Bare Minimum Mitigations for Autonomous AI Development | Position Paper |
| Mar 2025 | Large Language Model-Powered AI Systems Achieve Self-Replication with No Human Intervention | arXiv:2503.17378 |
| Dec 2024 | Frontier AI Systems Have Surpassed the Self-Replicating Red Line | arXiv:2412.12140 |

### Major Findings

- **December 2024**: First discovery that Meta's Llama31-70B-Instruct and Alibaba's Qwen25-72B-Instruct have already surpassed the self-replicating red line in 50% and 90% of trials
- **March 2025**: First systematic evaluation showing **11 out of 32 AI systems** can self-replicate, including models as small as 14B parameters running on personal computers

---

## Research Team

| Name | Role | Focus Area |
|------|------|------------|
| **Prof. Min Yang** | Principal Investigator | AI safety and agent autonomy research |
| **Dr. Xudong Pan** | Foundation Models | Agentic workflows and LLM-based autonomous systems |
| **Dr. Jiarun Dai** | System Security | Secure AI deployment and sandboxing techniques |
| **Dr. Geng Hong** | Penetration Testing & Agents | Red-team operations to test AI self-replication limits |

---

## Impact & Recognition

### Academic Impact
Our research has garnered significant attention from leading experts worldwide:

> "We just crossed a red line, one of the few that was relatively clear: AI can now self-replicate."
> â€” **Charbel-RaphaÃ«l Segerie**, Executive Director, CeSIA (France AI Safety Institute)

> "Self-replicating AI introduces a new dynamic in technological evolution and we should be careful that it does not lead to cancer-type digital niche construction."
> â€” **Michael Levin**, Distinguished Professor of Biology, Tufts University

### Awards & Recognition
- **Falling Walls Shortlist 2025**: "Breaking the Wall of AI Self-Replication" â€” recognizing breakthrough research addressing global challenges

### Media Coverage
Our research has been featured in major international media:
- **LiveScience**: "AI has crossed a critical 'red line' and has replicated itself... AI may already have the capacity to go rogue"
- **Forbes**: Coverage of AI self-replication and survival instincts
- **The Independent**: "Advanced AI system has crossed a 'red line' after successfully replicating itself without any human assistance"

---

## International Collaboration

### Workshops & Summits
- **July 2025**: Co-organized the International Workshop on AI Deception with SAIF and Concordia AI â€” the first in-depth exchange on AI deception between domestic and international scholars
- Signed the **IDAIS-Shanghai Consensus Statement** on Ensuring Alignment and Human Control of Advanced AI Systems

---

## Contact

- **Email**: whitzardindex@fudan.edu.cn
- **Institution**: Fudan University, Shanghai, China

---

## License

&copy; 2025 Project NVWA (å¥³å¨²). All rights reserved.
